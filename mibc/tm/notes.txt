Goals for this software:

Definitions:
Each set of data being processed by AnADAMA is called a 'flow'
A flow is composed of one (or more) runs numbers 1 thru n
  The number is based on how many times the flow was re-run due to errors or 
   new tool versions etc
Each run is composted of a number of tasks.
Each task contains input file(s), output file(s), and parent(s)
  who must complete prior to start

There should be a single json full DAG produced for each flow.
This DAG shouldn't change between runs.  Tasks that have (potentially)
completed should still be listled in the DAG.  The TM should
identify them as complete and update the GUI to reflect all
changes.

Eash task should have a unique id associated with it (hex number?)

Each flow should be identified by a unique name:
  <Datatype> + <Date?> and or <unique ID>
ex: 
/usr/local/anadama_flows/16S_kbayer_1428
/usr/local/anadama_flows/16S_kbayer_1428_1
/usr/local/anadama_flows/16S_kbayer_1428_1/run1
/usr/local/anadama_flows/16S_kbayer_1428_1/run2
/usr/local/anadama_flows/16S_kbayer_1428_1/run3
/usr/local/anadama_flows/16S_kbayer_1428_1/run3/<tasknum><shortname>
/usr/local/anadama_flows/16S_kbayer_1428_1/run3/graph.html
/usr/local/anadama_flows/16S_kbayer_1428_1/run3/js/...

Tornado changes:

In order to use tornado effectively, we need to modify the
current task management software:

1. use tornado process.subprocess for launching tasks.

2. no more looping in task mgr - should only wake up when
jobs finish?  What if jobs don't finish?  stuck jobs?
control through web gui?  Can we wake the task mgr 
periodically?

# background update every x seconds
    task = tornado.ioloop.PeriodicCallback(
            fx(x),
            15 * 1000)

